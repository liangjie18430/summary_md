# 说明

1. 热点AI机器人中有什么相关的难点
    主要是学习es的过程中可能会踩坑，里边的默认分词器就是单个词进行分类的方式。第二个是需要调试prompt，有时候prompt并不符合预期，需要针对业务场景做一些prompt的精细化优化

2. 优化prompt有没有一些什么经验
    * 会做假定是xxx的角色，提升prompt专业度
    * 写的要求尽可能的少和明确，当要求过多时，会出现一些要求无法满足的情况
    * 对于上述俩个都无法满足的时候，可以额外通过其他的LLM或者其他方式收集相关的数据集进行SFT。

3. action和reward是如何设计，有没有一些业界是可以通用的一些经验
    reward设计时需要考虑最后的目的，然后进行拆解，比如游戏最后的胜利条件是占领棋子点，那么占领棋子点的reward就可以拆解部分出来，然后拆出一些其他的比如战斗类的reward等，
    action设计中，有一个trick，因为需要考虑更多的精细动作，所以在精细动作的细节上，会在角度较小的时候，设置更密集的action，强化学习中，为了减少探索，需要将

滑动窗口=k中找最大值
可以直接查看leetcode中滑动窗口的最大值




# 二面

主要咨询了项目和基于强化学习的直播场景题：
    有一个场景，本身的action会有互动xxx的，然后目标是总观播放时长和gmv，播放时长会受到推荐过来的人数的影响，这个如何建模。
    答：状态部分因为肯定能拿到本身已有的，然后action部分都是定好的，主要看reward部分能否做一些拆解，首先gmv等之类的reward可能是比较稀疏的，这个时候可以通过一些相关性方法判断是否存在其他的指标和这个gmv相关，这样可以让reward转换为一些更小的更稠密的reward。
    而总观均时长变化较大，所以是不太适合进行相关的学习的，看能否做一些处理，比如推荐进来的人从进来开始到离线的时长，做归一化，可以权重小点，而本身自来水这样的，reward大点之类的，减少推荐所带来的影响，同时可以看看是否有reward可以排除这个推荐进来的人群的影响。

算法题：
    1. 使用梯度下降的方式实现计算sqrt(n)

    2. 实现一个矩阵乘法, 不能用matmul




# third interview
    场景题：
        数字人直播场景，action有一些发红包之类的，目标是为了用户的观看时长+gmv，如何通过强化学习的方式进行相关的设计。
    答：
        特征部分： 直播人群的一些画像类特征，
        action部分可以直接采用数字人可以做的一些操作
        reward部分时长需要做一些reward的设计防止方差过大，在gmv部分，因为是一个较为稀疏的奖励，所以可以做一些拆解，可以分析哪些指标的行为是和reward是相关的，可以做一些相关性分析，将这个稀疏的reward拆解成一些更加稠密的reward。比如是否互动区的氛围更好了之类的。


# HR
    不要说BaiDu太多的坏话
    需要准备的问题：
        失败的case、成功的case
    不要太咨询HRBP职级和薪资等，后续会有一个专门的HR负责这个薪资和职级的流程。
        职业规划：
            做一个有很强专业知识能力的技术管理，能上能下，持续学习
        离职原因：
            1、当前工作内容不太符合预期，这边岗位调整频繁，同时工作内容变成了数据分析，我也在这边工作了俩个月看看工作内容，对我的未来增益不大
            2、
        下一份工作的期望：
            有挑战，喜欢挑战难的事情，有收获，能够对自己的未来成长有一定的帮助. 从DeepSeek的人才构成和所做的事情可以看出，在算法领域，需要更多的创意，有想象力和创意的人，能够比墨守成规的方式获取更多的可能的创新的结果。
