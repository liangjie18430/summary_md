# 为什么选择从普通风格转换为ip风格的方案，和直接写模仿风格有什么区别？
    答： 首先ip的风格不太好量化，如果直接以ip的形式直接放入prompt，其实数据量不多，希望能够有更多从更多的普通的风格中，跑出来更多的基于ip风格的数据

# reward的设计方法
    主要还是做reward的拆解。从稀疏的，往更加能够提升reward出现的相关概率的方向走


# 风格化的评测
    主要看场景和使用要求，看是不是只要风格化好就行，还是希望能有风格化的同时，能够更多的保留历史知识（也是当时引入kl散度的原因, 因为智能npc的使用场景，就是希望还可以进行相关的闲聊）


# 在RLHF中，ref的模型的产出结果概率分布，能否提前通过离线的方式计算好？
