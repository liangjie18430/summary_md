# first
    有没有遇到过dpo中出现loss为0的, loss为零需要从常规的为什么loss为0来考虑
    本身DPO中数据语料中一定会出现差的value出来，所以有可能存在梯度消失的问题？
    
    使用SFT是否会出现过拟合？假设语料中出现"中国"还有和"的"的词的，是否都会出现过拟合？
    
    会从2个方面考虑，首先模型足够大，有足够的学习能力，而SFT中的语料较少，所以一定会出现相关的过拟合。而"中国"和"的"这种都会出现过拟合，但是"的"这种词的过拟合的程度应该不会有"中国"这种词过拟合严重。比如说和"中国"这个词出现的语料可能集中在"中国天安门"或者"中国北京"之类的词，分布更集中，而"的"的分布没有那么集中。


    3. 能否用大模型做一二三级标签分类
    推荐使用一些预训练好的embdding特征做cluster


算法题：
    密码锁，init_states=[0,0,0,0], target=[8,8,8,8], 有一些deadnodes = [[1,2,3,4]],求最小步数
