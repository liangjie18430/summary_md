论文解读

Real-time Attention Based Look-alike Model for Recommender System





# 一、look-alike

在读该论文前，需要先了解look-alike的概念。

定义：**即相似人群扩展，是基于种子用户，通过一定的算法评估模型，找到更多拥有潜在关联性的相似人群的技术**。值得注意是，**lookalike不是某一种特定的算法，而是一类方法的统称**，这类方法综合运用多种技术，比如协同过滤、node2vec等，最终达到用户拓展目的

[参考网址](https://www.zhihu.com/question/43566578)

特征和模型算法分为三种

1. 通过用户画像进行人群扩散。方式为给种子用户打变迁，利用相同标签找到目标人群
2. 利用分类模型进行人群扩散。种子用户为正样本，候选对象为负样本，训练分类模型，然后用模型对所有候选对象进行筛选
3. 利用社交网络进行人群扩散。利用种子用户的好友关系，将其标签传给社区中的好友，从而实现人群扩散。根据理解，应该是标签传递算法之类的。

主要分为三步：

1. 提交数据。广告主向DMP提交的一系列客群范围，一般以设备码和电话号码的形式存在，称为<font color="red">种子用户</font>。
2. 进行建模。以分类模型为例，种子用户在和DMP平台所拥有的用户数据<font color="red">进行匹配，排除非DMP用户</font>，将剩下的种子用户作为机器学习的正样本。
3. 输出拓展用户。根据广告主缩需要的目标用户量级，按模型机制输出数据。<font color="red">根据扩散量级需求，量级越小，包含的用户群体相似程度越近</font>。广告主可使用拓展后的用户数据包进行广告投放。



# 二、马太效应

[百科参考]([https://baike.baidu.com/item/%E9%A9%AC%E5%A4%AA%E6%95%88%E5%BA%94/70100?fr=aladdin](https://baike.baidu.com/item/马太效应/70100?fr=aladdin))

强者越强、弱者越弱





# 三、论文解读real-time attention based look-alike model



该模型是一个基于相似度的look-alike模型。论文中说的创新点是第一个实时的系统。

整体的设计范式是将复杂的预训练留给离线，线上尽量使用简单的方式。

## 3.1 产品形式

这片文章是针对看一看的，先了解了下看看的产品形式，看一看中有俩个形式

1. 朋友在看
2. 精选

其中精选是feed的推荐流的形式。

原始的推荐建模一般分为俩种形式：

1. (uid,iid,label)建模，无法解决预测那些没有uid和idd的
2. 针对uid和iid做一层抽象。即user_id可以使用年龄、性别、所处区域等来做user的embedding，item可以抽象成tag、topic等或者对item的。该方法存在对item的历史行为刻画不完整的情况。导致推荐结果趋向于CTR表现好或者PV表现好的item。

[中文参考](https://zhuanlan.zhihu.com/p/93558581)

## 3.2 论文目的

传统的原始特征抽象无法解决长尾问题，且存在头部效应，导致推荐边界收窄。

内容推荐场景中要求

1、内容时效性要求高，要求5分钟或者10分钟内要触达用户。

2、后悬剂更新频率高。每一份每一秒，都会有新内容。

模型需要达到如下的要求：

- 实时:

  新闻的时效性是一个非常重要的特性。

  新item无需实时训练。此方式和通过实时获取item点击的用户，然后使用用户id的embedding来进行avg后解决。根据该论文查看，新item冷启动的user个数和kmeans是相关的。和做实时特征比较类型，只是之前的实时特征为构建的实时特征，此处的实时为seeds user的embedding向量来构建实时特征。

- 高效：

​       保证CTR的前提下加强对长尾内容的分发，学习更具准确和多样性的用户表达。

- 快速：

  通过kmeans的方式来减少种子用户的个数，还有预计算的方式

## 3.3 如何解决

### 3.3.1 为什么用lookalike。

使用行为统计无法对item行为完整建模，信息损失太大。

Look-alike中的俩种建模方式

1、相似度计算。建模、性能好，但是准确度低

2、分类。准确度高，但是训练开销大。对于广告集来说是可以接受的，因为广告的后悬剂不大，更新频率也不高。

但是传统的lookalike不适用。

因为长尾的item曝光低，点击少，和look-alike中使用种子用户来拓展其他用户的行为一致，每个item也是使用一些seed users来进行表示，从而对当前的item拓展新的用户群体。







# 3.4 模型说明

借鉴了look-alike的思想，使用对item发生过行为的user来表示item。将传统的user2item模型切换为了user2users(注意是<font color="red">user和users</font>)模型。注意，针对每个item和对应的user，还是计算的一个score。

那么如何来获取一个高效的自适应的seeds representation。



整个模型的离线部分分为俩个部分：

- User representation learning:多域，可以参考you tube的DSSM论文的第一个阶段，只是中间加上了attention的机制。

  目标为点击了item之后，下一个要点击的item。

  使用attention机制主要是为了解决域的分布不均，有些域的行为过少。

- Look-alike：学习目标用户和候选item种子用户的相似度(item使用种子用来来进行来表示)。

那么是如何做look alike 学习的呢？

global info：用户群体的共性信息。种子群体自身内部的分布。采用的是self-attention机制。

local info: 种子群体和target user的个性信息。使用的是乘法attention，提取target user和种子用户群体中的相关部分，捕获种子用户的local info。

然后将俩个部分加权求和。来获取local&global info。

但是<font color="red">线上预测开销</font>过大，会大于1000ms。

采用了kmeans的方式来进行的优化。



## 3.5 指标

在该论文中有新定义一个指标：

precision@K：

公式为如下：

按照分数降序排序的前topk个推荐结果和用户点击过的item的交集(存在一些用户点击过但是没在topk结果中的)

除以  ：   K和用户点击过的item的个数中的较小值。







## 3.6 模型输入

因为模型分为俩个部分，所以需要弄清楚俩个不同部分的模型输入。

在当前的论文中，候选的items为最新的新闻，手动打上标签的高质量文章，还有长尾的用户感兴趣的内容。。

这些是通过实时的pipeline，在线的更新候选的数据库。对每个用户都会有几千个候选集，同时。对于每个候选集，都会同时的采用异步的方式更新候选集所对应的seed items。



在线服务部分：通过计算当前user和候选item的相似度来进行的推荐。



整体分为三个部分，离线处理，在线异步处理，和在线服务。

### 3.6.1 离线训练

- **user represent learning**

当前部分的特征会拿到user在各个领域所对应的特征，包括阅读的文章、播放的视频、购买的物品、播放的音乐，订阅等。每个不同的领域中都会包含不同的离散特征和连续特征。



分为俩个部分：

1. 左侧

左侧同样包含俩个部分的内容，一个部分为连续特征，连续特征直接输入。

离散特征

通过embedding_lookup的方式映射到一个向量。离散的特征中包括单值的离散特征或者多值的离散特征，对于单值的离散特征，直接使用embedding lookup映射到向量即可。而对于多值的离散特征，可以通过embedding lookup后使用求avg的方式，来获取当前field对应的特征。



连续特征

连续特征直接使用最大最小归一化进行处理。



- **look alike learning **





### 3.6.2 线上异步服务  

参考4.3 每5分钟更新一次，



## 3.7 线上流程

线上流程涉及到特征的保存和特征的使用部分。

### 3.7.1 特征保存









### 3.7.2 特征使用













# 四 问题

1. 没有说k-means的k线下定为20，线上定为100，不知道是否是做AB选取的。

在论文中有选取5，10，20，50，100进行的测试，当指标上升不再多时，选取的k中

1. 对比的基准模型是用户画像匹配模型，而且是非实时的，不是和其他的实时策略进行的对比。
2. 该模型的item冷启动问题，使用的user和item的语义信息，此处的语义是否也存在冷启动
3. 切换到look-alike模式，也是需要到百级别，是否是因为kmeans设置的为100，不然无法聚类到100.

















# 五、其他问题确定



1. kmeans的中心是绑定在item上的吗

根据了解到的情况，kmeans是绑定在每个item上的，即每次计算聚类中心时，不是所有的user来计算聚类中心。而是根据每个item所拥有的user_id lists来计算聚类中心















