# 反向传播

0. 理解前向模式求导和反向模式求导
	- 参考网址:https://zhuanlan.zhihu.com/p/25081671
1. 先了解各项公式中内容的定义：
 各定义参考网址:https://blog.csdn.net/qq_45021489/article/details/90297404
 哈达玛积: 参考网址:https://www.jianshu.com/p/c08c5c5fc80d
 w(l): l-1层神经元到l层神经元的权重
 b(l): l层神经元的偏置
 z(l): 表示l层的输入，即上一层经过激活函数后的输出\*权重+偏置
 a(l): 表示l层神经元的输出σ(z(l)),即z(l)经过激活函数的输出
 L: 代表神经网络的最大层数
 C: 实际样本标签和对应层层输出的损失，二次代价函数或者logloss等。
 δ(l)(读作delta): 第l层神经元产生的错误，定义为C对z(l)的导数
 σ(z(l))(读作sigma): 为激活函数对输入的偏导数
 注意公式δ(l)可以递推求出
2. 为什么第l层神经元产生的错误会如此定义
 参考网址:https://blog.csdn.net/junjun150013652/article/details/80748759
 δ(l)为自身定义的，不需要推导。给神经元输入修改一点，则输出也会相应变化，会在后续的神经网络中也产生对应的变化(其实简而言之，就是在推导过程中发现可以把这个部分抽象出来统一，就这么定义了)。

3. 注意求导
 - 求导中有直接针对激活函数a的求导，注意查看求导符号的下标。注意激活函数针对输入的求导。
 - 如何理解反向传播中的求和，可以从前向模式求导中理解。
4. 反向传播示例
 参考网址: https://www.cnblogs.com/wlzy/p/7751297.html
 上述的网址中有反向传播算法的公式推导。

