# 一面
强化学习：
    问了经验回放的优缺点
    问了ddpg中的target网络和actor critic网络的loss目标
    为了为什么这么建模

推荐：
    主要问了频道推荐的迁移
    问了各种指标，为什么做这件事之类的
    为了mmoe，ple的好处
    

算法：
    问了最长回文子串
    问了时间复杂度和空间复杂度
    问了能否使用动态规划的方式做

# 其他部门一面
    业务部分：抖音热点挖掘
    - 如何解决幻觉问题
    - RAG如何做
    - 
    俩个链表最近节点    



# 二面
    

    - 天水｜哈尔滨｜淄博都火了，如何挖掘下一个热点
        * 从一个当前消费降级的背景来看，可以先看一下当地的消费水平，像淄博｜哈尔滨和天水，都是当地的消费水平比较好
        * 还需要看当地的民风
        * 需要看当地的人有没有给家乡做不做宣传
        * 平台侧也需要给定一定流量的倾斜
        * 本身热点事情的爆发具有一定的不可预测性，在做流量倾斜的时候可以多尝试几个

    - 算法
    给定一个字符串，判断合法的ip数, 比如"255234910"，可以分解成多个ip地址，如: "255.234.9.10", 还可以分解成"255.23.49.10"有多个结果


# 三面
    - 不同的团队的经历可以在算法上带来什么样的提升
        * 在针对问题建模的时候可以有更多的一些视角。
    - 如何看待热点挖掘
        * 热点还是很重要的，本身热点可以给平台带来很多流量
    - 如何做一些热点挖掘
        * 从俩个方面看，一个是一些出圈的热点，一些是不出圈的热点（这些可以理解为一些局部的热点，比如微博里的热点）。总体热点的挖掘可以先做一些融合，然后统计近期内的分享数、平均数、观看数，近期的热点一定是这些指标比较高的。除了做总体的热点挖掘外，还是需要做一些垂直领域的热点挖掘的，因为每个人除了对出圈的热点数据的消费需求外，肯定也会有垂直领域的一些热点消费需求, 所以对于不同的人来说，热点应该是不同的。
    - 如何用LLM对一些数据形成一些分析类的文章, 比如每年春节，就可以用一些数据形成不同的去类哪里进行消费之类的
        * 可以先使用其他的方式来做兜底输出
        * 在使用大模型的时候，可以使用SFT的方式，先通过之前的一些已有的数据，形成一些垂直领域的数据集，然后再进行SFT相关的操作。
        * 第二种使用大模型的方式，可以采用RAG+Agent的方式做尝试，可以俩个团队同时从这俩个方向做（这样可以体现一定的领导力）
    


    - 反问，问了一下当前团队是如何做热点挖掘的
        也是从多个角度，召回｜融合｜排序（排序也会是一些类似多目标的方式）｜审核。
