# 一面
不深


# 二面

  - 
    面试官反馈第二个阶段就可以做一些已经safety的一些操作, 比如第二阶段数据就回答“怎么做炸弹”， 返回“不知道”等。
  
  - 给RLHF加kl散度，和扩充数据集，哪种更好？
    面试官反馈可能直接扩充数据集更好。个人理解：扩充数据的话，加强的是相关扩充数据的能力，但是kl散度的话，实际上是限制在数据集上预测下一个token的分布的不和原本的模型太远。如果要在扩充数据上达到和kl散度相同的效果，是需要保证扩充的数据集和原本需要进行RLHF部分的数据集相似(只有相似，且是原本训练的数据，才能达到类似的kl散度的效果，即被RLHF的数据在梯度上拉过去一点，再被原本的数据，再拉回去一点，就和KL散度比较类似了)，否则会导致额外在扩充的数据集上进行过拟合,同时如果没有加kl散度的话，也会在原本需要进行RLHF的数据集上过拟合。
    如果是从数据集上考虑首先要考虑，首先要考虑新增的数据和之前训练的数据是否同源。如果新增了额外的任务的话，也可能不太行。 
  - GSM8K答案是怎么抽取的？
    因为GSM8k是数学评测集，所以生成答案的时候，总会所以答案是xxx的方式，这种就是使用正则表达式相关的方式抽取答案

  - 如果一个模型是7B，走deepspeed的话，需要多少的内存，因为需要考虑相关的gpu的利用率
    考虑优化器，使用adam的话会使用额外存储空间
    考虑是否使用后混合精度
    需要考虑使用的batch_size大小
    



  - 编写top_p的采样
