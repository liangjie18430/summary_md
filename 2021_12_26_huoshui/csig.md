# 说明
此处为面试csig的一面记录


# 如何解决超参数的融合公式设计的纲量问题
注意：在美团的超参数设计中，俩个都是二分类的问题，所以是直接设计了一个类似于点击率+点击率\*转化率的目标，这个是属于线上的融合参数部分，但是对于奖励的设计中，可以直接使用类似于时长等目标进行reward的设计

在本人设计的超参数上，可以将时长的目标除以视频本身的物理时长将其归一化到[0,1]中，保持和点击率在一个纲量上。


实际上更深一步可以直接使用模型的预测值来评估不同模型的预测分布，比如A的二分类目标集中在a点和b点(二分类目标一般都会是双峰分布，因为本身是需要预测0-1之间)，B的二分类目标集中在c点和d点，然后根据分布来设计更合理的融合公式


在qq看点分享的ppt中，针对于超参数的设计(本身都是一些二分类的问题，时长为转换为二分类+权重的方式进行的实现)，


同时会分为三个阶段，第一个阶段，统计各个分段的用户在不同行为上的表现，设计固定规则，分为时长类用户、互动类用户、点击类用户等，不同的用户使用不同的超参数融合公式

# 在推荐中遇到的主要问题
	物品冷启动和user冷启动的问题，本身内容推荐有很多内容都是长尾的，在内容上使用爬坡机制，或者通过引入外部的item或者user的相关特征，user侧一个新启动的业务中需要保证效果，一般是使用热门的进行兜底之类的

# 离线表现和线上表现不一致时怎么解决
    * 检查是否存在特征穿越问题，特征穿越到导致离线auc的评测很高，但是在线上表现不好
    * 检查是否负样本比例过高，在负样本比例过高的情况下，很容易造成auc过高（为什么？）,因为分类更容易了，学的更好了，那么auc对正负样本比例不敏感是怎么回事。可以参考这个网址：https://tracholar.github.io/machine-learning/2018/01/26/auc.html#auc%E5%AF%B9%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E6%AF%94%E4%BE%8B%E4%B8%8D%E6%95%8F%E6%84%9F,注意关注重点，是针对测试集而言，auc对正负样本比例不敏感，如果是训练集的话，改变了原本的样本分布，会导致训练的模型变化。
	利用概率解释，还可以得到AUC另外一个性质，对正负样本比例不敏感。 在训练模型的时候，如果正负比例差异比较大，例如正负比例为1:1000，训练模型的时候通常要对负样本进行下采样。当一个模型训练完了之后，用负样本下采样后的测试集计算出来的AUC和未采样的测试集计算的AUC基本一致，或者说前者是后者的无偏估计！ 如果采样是随机的，对于给定的正样本，假定得分为，那么得分小于的负样本比例不会因为采样而改变！ 例如，假设采样前负样本里面得分小于的样本占比为70%，如果采样是均匀的，即的负样本和的负样本留下的概率是相同的，那么显然采样后这个比例仍然是70%！ 这表明，该正样本得分大于选取的负样本的概率不会因为采样而改变，也就是是不变的，因此，AUC也不变！

相比于其他评估指标，例如准确率、召回率和F1值，负样本下采样相当于只将一部分真实的负例排除掉了，然而模型并不能准确地识别出这些负例，所以用下采样后的样本来评估会高估准确率；因为采样只对负样本采样，正样本都在，所以采样对召回率并没什么影响。这两者结合起来，最终导致高估F1值！

	* auc体现的一个整体间的排序能力，可以尝试使用gauc等进行评测
	* 可以参考这个网址：
		https://www.zhihu.com/question/305823078
		1.  是否校验过相同pv，线上预估值与离线预估值之间的差异性。（用来check各种因素最终造成的不一致影响面，可能是模型，特征，或者其它bug）2.  nn model ctr分布相比上一版本(LR？)分布的变化，可以用一天的数据，绘制ctr的概率分布图，分析模型预估值的分布变化情况。(一般情况下线上都采样了和模型耦合的一些ctr calibration、截断、以及某些出价逻辑，如果nn ctr分布产生较大变化，而对应的策略没进行调整，最后得到的效果是可能出现一些奇葩情况)。
	建议参考iwtbs的回答：
	“ 离线场景下我们会优化很多离线模型，也会用诸如准召、auc等指标评估模型效果。很多时候我们会遇到，离线auc涨了一些，但是上了ab后发现指标波动或者涨幅不如预期，那么可能是什么原因呢？”本文一些内容是自己工作中遇到的，也有一些内容会参考其他的博客、论坛，尽量保证内容的全面性。1. 特征不一致这种情况是最常见的。其实我工作之前也不太能理解，代码不都是自己写的吗，而且特征没对齐难道不报错吗？但是实际工作中，尤其是在大厂，工程方面一般是工程团队做的，对于算法同学来说就是在UI界面上点点鼠标，虽然简化了操作但是却很容易忽略一些bug。代码/操作bug以我举例，我最近用Albert优化了一版nlp模型，输出了一个dense特征，并且加入到融合模型中。batch训练的时候auc涨了不少，但是上线后流式训练结果波动，后来debug的时候发现是线上特征根本没传过来，可能是服务端挂了，也可能是操作平台某个步骤略过了，或者压根slot没对齐等，这种错误自己打比赛可能很难遇到，但是工作中还是很常见的。时间延迟一般特征我们要做正排，然后让模型去取。但是由于很多特征我们都是开的周期任务（比如日更新），数据量大的时候正排表生成挺慢的。之前有一次我就发现连续正向的指标那天负向了，后来发现是资源不充足sql一直排队，已经到第二天中午了特征表还用的前一天的，这种情况下显然是会出问题的。为了减少类似问题发生，首先你要仔细得在上线后排查一下特征传输是否为空，然后尽可能在线实时请求打分的时候落地实时特征，训练的时候就不用特征拼接，只需要根据正负样本生成策略处理一下instance的label。2. 离线本身就有bug还有一种原因是，本身你在离线训练的时候就有bug，所以指标提升不置信，这种也挺常见。数据穿越比如你拿1-7号数据训练，但是你的测试集是7号，那么结果一定偏高，一定要用8号以后的数据测试。特征穿越常见的是使用和label强相关的特征导致的数据泄漏，更暴力的可能把index搞成特征了（狗头保命）过拟合可能只是恰好选到了一个比较容易拟合的测试集，所以最好多次选取。同时训练的时候观察曲线，不要验证集过拟合了还在训练。这里也有一个比赛的trick叫‘对抗验证’，听我一个比赛大佬同学说还比较好使。3. 离线提升不置信评估指标不合理首先我们要有业务sense，离线设置的指标是否能跟线上真实对应。比如你离线优化ctr模型的auc，那么线上就关注ctr的线上指标，而cvr、留存等都没有关系。其次，对于线上目标，我们是否可以用更好的离线指标来对应？我同事之前做多个position的整体排序优化，那么相对于AUC和GAUC，使用NDCG就更加合理盲目加特征工作中我们可能会做大量的特征，然后加进去train模型看效果涨一点点就觉得有效果，但可能这只是波动，线上也大概率没效果。正确做法是看看权重大的特征是否真的合理，权重小的特征应该被删掉（如果这是个合理特征，一定不能删掉）4. 线上降低不置信数据量不够如果你的场景本身数据量就不多，那么波动其实非常大，这种线上指标是不可靠的。我之前实习做的一个场景，由于产品规划问题流量直接给我砍到了1/10，之后我的ctr/cvr就开始疯狂波动，ab的结果实验组前一天+40%，后一天+10%司空见惯。举个极端的例子，实验组对照组都是一万人，开aa实验应该都是10个人购买；实际上实验组11个人购买，对照组9个人购买。其实这种多一个少一个都是波动，但是你计算一下指标，0.0009和(0.0011-0.0009)/0.0009=22.2%实验开的不好ab可能是不够的，因为产品本身就可能会受到各种环境的影响有指标变化，所以可以考虑AABB、反转等。5. 数据分布不一致首先我们要清楚的一点是，离线训练模型的本质是，用公式去拟合训练样本集合的分布。那么离线指标提升了，只能说明对于这个样本分布我们找到了一个更好的公式去拟合，可是训练样本分布并不等同于真实样本分布。其原因有很多，比较常见的是我们在处理数据经常会用负采样，可是这种采样哪怕再均匀也一定有偏；其次推荐场景下通常我们会选取展示未点击作为负样本的一部分，那么未展现的样本我们并不知道是否会被点击，这不就是让新模型去拟合旧模型么，旧模型打分低的部分在新模型训练样本中还是负样本，很明显也不太好。（说到这里就提个思考问题，大家觉得ctr模型里召回/粗排/精排阶段，正负样本该如何选取，为什么不同阶段会有区别）那么如何解决呢搞一个无偏标注的测试集。这个具体问题具体分析，有的场景不太好搞，一般特殊子模型我们会有专门人员来标注无偏的数据集。ctr模型感觉不好弄，可以考虑对新模型产生的样本上采样。模型融合。（这个方法我是看别人博客写的，没试过）比较trick的方法，用新模型预估分数和老模型预估分数直接在线上做线性融合，刚上线的时候权重主要在old模型，然后逐渐加大new模型权重。6. 业务battle这种情况其实工作前完全没考虑，还比较有意思。就是还是那句话，流量基本是一定的。比如你在优化A场景，B场景和A场景是相辅相成的，而C场景和A场景是对立的，那么你也要时刻关注其他几个相关场景的模型改动，如果B掉了+C优化了，那么哪怕你A本身是可能涨了一点点，但是现在只能降了。（比如以前写的文章提到的，如果你优化了关注页面，间接提高了粉丝价值，那么涨粉速度一定是降的，feed的一些指标就可能有影响。
# spark中数据不平衡怎么解决

实现加key进行使得shuffle更加平均

其他方式reduceByKey替换groupByKey,会现有一步融合，可以减少shuffle



